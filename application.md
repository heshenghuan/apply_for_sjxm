# 面向微博语料的中文词法分析技术

## 一、立项依据

### 1、项目来源

本项目来源于对“大数据”时代互联网海量文本语料资源进行有效利用的需求，研究海量语料资源条件下的微博语料的中文词法分析问题。中文词法分析主要包括中文分词、词性标注和命名实体识别任务，而微博语料的中文分词和词性标注问题是近年来的研究热点，也是当前工业界亟待解决和应用的热点问题。面向微博语料的中文词法分析技术，是工业界很多基于微博的项目（如突发事件检测，事件追踪，舆情分析）的基础，因为中文语料的特殊性，大多是中文自然语言处理任务都必须建立在已分词（词性标注）文本的基础上才能完成。因此，项目的完成将有助于推动互联网相关自然语言处理任务的研究，具有重要的理论意义和应用价值。

### 2、项目研究意义

随着计算机与网络技术的发展，网络社交媒体（social media）不断壮大，并且用户数目不断增多，每时每刻都有数量庞大的信息在网络上产生、传播。微博（Weibo, MicroBlog）是一个基于用户关系的信息平台，用户通过建立关注、被关注、相互关注，可以轻松获取、分享和转发微博平台上海量的微信息。这一切通过操作手机或使用浏览器就可以简单实现。

然而微博上包含的海量语料，是无法直接用于计算机处理的。而且，与新闻报纸等语料相比，微博语料具有以下显著特点：第一，文本长度短小但数量众多；第二，具有不规范性，文法通常是非正式的，语言偏口语化和生活化，带有缩写、拼写错误、不规范用语、噪音及表情符，增加了用户对有价值信息发现的难度；第三，微博短文中通常包含显著的个人意图和明显的个人主义情感色彩；第四，具有半结构化的特点，除了文本内容还包含一些元数据，如发布时间、收藏数量、转发量等等；第五，微博文本通常是某对话线索（conversation thread）中的一个发言或回复，因此每个线索包含多个微博文本，形成充足的上下文；第六，微博文本中因对话线索而形成丰富的上下文，常常有大量的省略和指代【1】。

此外，微博不同于传统媒体，它的发布者和接受者之间无显著区别，拥有完全平等的发言权。微博内容不受题材限制，对用户表达能力要求极低，用户能用只言片语，反映自己的心情即可。可以说，微博上语料的质量参次不齐，但是基于微博用户的庞大数目，微博每时每刻都在产生着海量的语料资源。然而这些未标注的语料资源是无法直接应用的，因此需要一个高效准确的中文词法分析技术对这些语料进行处理、分析和标注。但目前，还没有较为成熟、完善的现有的中文分词（Chinese word segmentation）算法能比较高效准确的处理微博语料。因此，我们现在面对的局面是空有海量的微博语料却没有有效的手段去利用这些资源。故开发一个面向微博语料的中文词法分析技术（包括中文分词，词性标注和命名实体识别等）不仅有重大的理论意义，而且具有使用价值。

// 研究意义在ref_1中有很多

### 3、国内外研究现状、水平和发展趋势

#### （1）国外学术研究现状

早期与微博文本相关的工作集中在语言分析方面。(Java et al., 2007)对微博的概念和作用进行了总结和探讨，介绍了微博的即时性、共享性、快速传播等特点，并从各个角度统计了微博在近年来的使用增长情况【9】。他们根据用户间的关系，阐述了哪一类的用户会分享相同的微博信息。(Kwak et al., 2010)讨论了微博的出现，作为一种社交网络或是一种新闻媒介对世界的影响【10】。并全面统计和剖析了从Twitter出现的到文章发表的三年来，Twitter的所有相关数据，包括Twitter的日发布量、发布总量、使用人数等。(Ellen, 2011)则对微文本(mircotext)进行了特征分析，认为微文本具有“短”、“文法不规范”和“半结构化”等特点【11】。这些工作，为研究者了解并把握微博文本的特征提供了重要依据。(Locke, 2009)将命名实体识别引入到微博文本的研究中，采用分类的方法将命名实体分为三个不同的类别（人名，地名，机构名）【12】。他指出，微博文本由于具有与普通文本许多不同的特征，所以在进行特征选择时，应该选择微博文本所特有的特征，再进行分类。实验证明，该方法取得了一定程度的提高。

在初步了解了微博文本的语言特点后，研究者们开始尝试对其进行处理。由于微博文本字数少，区别于普通文本的特点很多，所以在大多数使用机器学习的方法对其进行处理时，尝尝会发生严重的数据稀疏问题，对性能产生影响。于是,研究者们对解决数据稀疏问题进行了一 些尝试。(Sriram et al., 2010)等考虑到微博文本区别于普通文 本的特征,共选取了八类特征(即作者信息,发布时 间,标志符号等)【13】。加入这些特征之后，算法的性能得到了显著提高，改善了数据稀疏的问题。

可以发现，大多数研究者都对微博文本采用了特殊的特征工程(special feature engineering)，希望可以实现更好的特征表示和处理效果。这说明国外的学者对于微博文本的处理，普遍认为应该是用特殊的方法，而不是使用同普通文本一样的处理方法、工具等。但大多数国外研究者研究的主要方向是面向微博语料的文本分类和聚类、信息抽取、话题检验和情感分析等。这主要是由于国外研究者的微博语料来自于Twitter(一家美国社交网络及微博客服务的网站，是全球互联网上访问量最大的十个网站之一)，其用户大多数为国外人员，且大部分语料资源是英文等不需要进行分词的语料，因此对于微博文本的词法层面的研究几乎没有。但他们的研究思路和成果对于中文微博语料的研究有很好的借鉴意义。

#### （2）国内学术研究现状

不同于英语、葡萄牙语等语言，中文的词与词之间没有明显的分隔符号。而词又是理解句子的最小单位，这就导致分词成为中文信息处理非常重要的第一步。面向传统语料的分词系统已经十分成熟，并提供了词性标注和命名实体识别等功能的整合。然而，面向微博语料的分词、词性标注和命名实体识别却刚刚起步。这一方面是由于微博语料的特殊特点，另一方面，最主要的原因还是由于训练数据的匮乏。由于微博上拥有海量的语料资源，而人工标注数据费时费力，但经过人工标注、校对过的数据又是训练一个机器学习算法必不可少的，这就导致了矛盾的产生--我们需要数据却没有足够的数据。

为了解决这样的矛盾，(Zhang et al., 2012)提出了一个基于线性时间复杂度的增量模型的分词算法【4】。他们采用的是基于词的分词算法，同时使用了丰富的特征，包括：字特征(character-based features)，词特征(word-based features)和其他容易使用的可能特征。他们首先使用人民日报语料训练了一个通用目的的分词、词性标注联合模型，之后使用这个模型产生的结果作为最终微博分词模型的特征。并且，各种词汇表特征，例如词典和熟语、成语表也被用于对微博数据的分词。有关URL和特殊字符的处理也被引进。(Wang et al., 2012)首次将条件随机场（Conditional Random Fields）模型用于解决中文微博语料的分词问题【3】。他们也同样遇到了训练语料匮乏的问题，但考虑到文本语言的独特性，他们提出了一些方法让CRFs模型更适用于微博领域的分词。具体来说，他们不仅设计了最好的特征模板，而且使用了新的6-tag标注集，外部一元词典信息和其他领域语料来提升系统在中文微博语料上的分词性能。(Jing et al., 2012)提出了一些有关微博语料上中文分词的优化规则，并从实验结果中得出结论：这些优化规则十分有用【8】。优化规则包括：（1）计算新词的出现频次，添加高频新词进入词典；（2）添加常用的标点符号组合使用例子进入词典；（3）原始系统不能很好的处理有关时间的字符串，因此建立了一套时间模板（Time Templates）用于匹配时间字符串；（4）对于包含“http”这类关键字的URl字符串进行处理。

目前国内研究者们对于微博语料的词法层面的工作，大多数都使用了添加外部语料、新型特征模板和规则化处理等方案。实验结果表明，这些方向对于提升算法的性能有一定的帮助，但还有很大的提升空间。

### 参考文献

1. 张剑峰, 夏云庆, 姚建民. 微博文本处理研究综述[J]//中文信息学报, 2012, 26(4):21-27.
2. 石秋慧. 微博热点话题抽取及其情感分类[D]//哈尔滨工业大学, 2014.
3. Wang L, Wong D F, Chao L S, et al. CRFs-based Chinese word segmentation for micro-blog with small-scale data[C]//Second CIPS-SIGHAN Joint Conference on Chinese Language Processing. 2012: 51-57.
4. Zhang K, Sun M, Zhou C. Word segmentation on Chinese mirco-blog data with a linear-time incremental model[C]//Second CIPS-SIGHAN Joint Conference on Chinese Language Processing. 2012: 41-46. 
5. 于清, 阿里甫·库尔班. 微博语料分词及标注方法初探[J]//新疆大学学报:自然科学版, 2013(1).
6. 邱泉清, 苗夺谦, 张志飞. 中文微博命名实体识别[J]//计算机科学, 2013, 40(6).
7. Huiming D, Zhifang S, Ye T, et al. The CIPS-SIGHAN CLP 2012 Chinese Word Segmentation on MicroBlog Corpora Bakeoff[C]//Second CIPS-SIGHAN Joint Conference on Chinese Language Processing. 2012: 35-40.
8. Jing Z, Degen H, Xia H, et al. Rules-based Chinese Word Segmentation on MicroBlog for CIPS- SIGHAN on CLP2012[C]//Second CIPS-SIGHAN Joint Conference on Chinese Language Processing. 2012: 74-78.
9. Java A, Song X, Finin T, et al. Why we twitter: understanding microblogging usage and communities[C]//Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 workshop on Web mining and social network analysis. ACM, 2007: 56-65.
10. Kwak H, Lee C, Park H, et al. What is Twitter, a social network or a news media?[C]//Proceedings of the 19th international conference on World wide web. ACM, 2010: 591-600.
11. Ellen J. All about Microtext-A Working Definition and a Survey of Current Microtext Research within Artificial Intelligence and Natural Language Processing[J]. ICAART (1), 2011, 11: 329-336.
12. Locke B W. Named entity recognition: Adapting to microblogging[J]. 2009.
13. Sriram B, Fuhry D, Demir E, et al. Short text classification in twitter to improve information filtering[C]//Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval. ACM, 2010: 841-842.
14. Jiang W, Huang L, Liu Q. Automatic adaptation of annotation standards: Chinese word segmentation and POS tagging: a case study[C]//Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1. Association for Computational Linguistics, 2009: 522-530.
15. Hatori J, Matsuzaki T, Miyao Y, et al. Incremental joint approach to word segmentation, pos tagging, and dependency parsing in chinese[C]//Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1. Association for Computational Linguistics, 2012: 1045-1053.
16. Qian X, Liu Y. Joint Chinese word segmentation, POS tagging and parsing[C]//Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics, 2012: 501-511.
17. Ng H T, Low J K. Chinese part-of-speech tagging: One-at-a-time or all-at-once? word-based or character-based?[C]//EMNLP. 2004: 277-284.

## 二、实践目标、实践内容和拟解决的主要问题

### 2.1 实践目标

本项目的目标是开发一个面向微博语料的中文词法分析系统，主要包括以下三个主要部分：中文分词，词性标注及命名实体识别。针对微博语料的特点，提出适合微博语料的中文分词、词性标注及命名实体识别的模型和算法。最后，基于上述技术实现一个高性能、高效率的微博语料中文词法分析系统。

### 2.2 实践内容

根据上述研究目标，本项目主要进行下列三个方面的研究：（1）微博语料获取与预处理技术；（2）微博语料上的中文分词及词性标注算法研究；（3）微博语料上的命名实体识别技术。

#### （1）微博语料获取与预处理技术

微博语料的获取目前主要有两种方式，第一种是使用新浪微博官方提供的接口获取，第二种是通过网络爬虫进行网页抓去获取微博语料资源。因为微博语料的特殊性，其中含有不少繁体字，首先需要通过预处理转换成简体。之后我们需要结合具体的数据格式，利用微博文本半结构化的特点，事先识别出微博文本中的特殊字串和元数据，例如“:D”（表示开心）等字符表情、表情符号、网页链接、用户id信息等等，并用特殊的标识符代替，在分词时可以减少误识别的产生。

#### （2）微博语料上的中文分词及词性标注算法研究 

现有的中文分词工具有很多，但都不是基于微博语料训练得来的。因此它们在对微博语料这一特殊文本进行分词时，分词器的性能不尽人意。因为微博语料的特殊性、文法的不规范性，进行分词时需要特殊对待，主要包括以下几个方面：1.使用新型特征模板，发掘更多可利用的语料特征，使模型能更好地适应微博语料；2.使用外部字典信息，如成语字典、俗语字典或网络用语字典，提高模型对未登录词（Out-of-Vocabulary）的识别能力；3.使用新词发现算法或工具，与分词算法相结合，使分词算法能够一定程度识别新词；4.建立高频词词典，程序可以在使用的过程中自动维护，保证算法对新词的发现能力。

词性，用来描述一个词在上下文中的作用。词性标注（Part-of-Speech或POS tagging）是指对于句子中的每个词都指派一个合适的词性，也即确定每个词是名词、动词、形容词或其他词的过程，又称词类标注或者简称标注。在汉语中，词性标注比较简单，因为汉语词汇词性多变的情况比较少见，大多词语只有一个词性，或者出现频次最高的词性远远高于第二位的词性。而微博语料有其自身的特殊性，文法的不规范性是导致词性标注错误的主要原因之一，此外还有特殊符号、表情符号等问题。本项目需要开发适合于微博语料的分词、词性标注算法，使之能够达到较使用传统语料训练出的分词和词性标注算法更好的结果。这就需要根据微博语料的特殊性，采取对应的、有效的措施，通过预处理、特征抽取与表达等手段，开发合适的分词、词性标注算法。

#### （3）命名实体识别技术研究

在对微博语料进行分词和词性标注之后，本项目需要将已分词的语料输入到命名实体识别系统中进行识别。命名实体主要包括三类：人名，地名，机构名。中文命名实体大多数具有四个特点：1.各类命名实体的数量众多；2.命名实体的构成规律复杂；3.嵌套情况复杂；4.长度不确定。这些特点都给命名实体的识别带来了很大的困难。而且微博语料中，常常出现大量的人名、地名和机构名，这让对微博语料的命名实体识别显得尤为重要。不仅如此，微博作为社交媒体，充斥这大量网络上的新词，例如：书名、歌名、电影名以及一些缩略语。这些新词中大部分是可以作为命名实体识别的。

本项目具体的识别过程为，算法的输入是已分词的句子，系统通过特征模板抽取特征，之后使用机器学习算法进行识别，最后利用维特比算法（Viterbi Algorithm）以及简单的模式识别得到最终的识别结果。这里，本项目采用的是层叠隐含马尔可夫模型。不同于单层隐含马尔可夫模型，本项目不是一次将语料中的人名、地名、机构名识别出来，而是分层处理。第一层隐含马尔可夫模型主要用于识别人名，第二层用于识别地名，第三层则用于识别嵌套情况最为复杂的机构名。这三层隐含马尔可夫模型，自底向上识别的命名实体的嵌套情况越来越复杂，因此采用了分层的方法处理，以免在一次处理过程中出现错误。

### 2.3 拟解决的主要问题

#### （1）如何有效获取海量微博语料数据并作预处理

#### （2）如何有效进行微博语料的分词和词性标注

中文的词性标注技术已经十分成熟，但面向微博语料的词性标注技术却与传统语料上的词性标注有些许区别。与传统语料不同，微博语料长度较短且未登录词较多，同时还可能带有大量的特殊符号或表情，这对词性标注产生了许多干扰。特别是特殊符号及表情符号，这类符号往往具有特殊的表征意义，例如“^\_^”（表示开心）、“=\_=”（表示无语）、“>o<”（表示愤怒）等等。这类符号如果不进行特定的预处理，将会对词性标注系统产生较大的干扰，导致结果不准确。

#### （3）如何有效进行微博语料的命名实体识别

## 三、可以的实践思路与方法、技术路线、实践方案（含创新性）及其可行性分析

### 1、实践思路与方法

（1）文献分析法：本文将通过学校图书馆、互联网多种途径搜集关于基于微博语料的中文分词、词性标注、命名实体识别的研究资料。

（2）案例分析法：对国内外各大分词系统，词性标注系统，命名实体识别系统对微博语料的处理做调研。

（3）比较研究法：不断测试各种算法，对比性能，分析结果，不断改进。

### 2、技术路线

如图1，本项目一开始先对语料进行中文分词，同时维护相关词典

### 3、实践方案

#### （1）基于网络爬虫的微博语料获取技术

#### （2）面向微博语料的文本预处理技术

#### （3）基于感知器的中文分词算法

#### （4）基于遗忘的新词发现及词典维护算法

#### （5）基于隐含马尔可夫模型的词性标注算法

#### （6）基于隐含马尔可夫模型的命名实体识别算法

### 4、可行性分析

- **市场可行性**：
- **技术可行性**：本技术主要采用了经典的感知器算法、隐含马尔可夫模型及维特比算法用于分词、词性标注和命名实体识别。相关模型都在这些领域的实践和论文中得到了有效的结果，因此技术具有很高的可行，没有问题。

### 5、本项目的特色与创新之处

本项目的特色与创新之处主要体现在以下几个方面：

- 针对以往的微博语料的研究往往将分词、词性标注和命名实体识别分开做的缺点，实现了集成模型可用于对语料的同时分词、词性标注和命名实体识别，有助于提高各个任务的准确性。
- 针对微博语料的特点，开发新型特征模板及算法，适应微博语料的内容多样、文法不规范等特点，有效利用语料的内容进行可靠的中文分词、词性标注和命名实体识别。

## 四、实践工作的总体安排及进度

1. 2016年5月5日 - 2016年8月5日
   - 完成总体方案
   - 实现分词系统、词性标注系统、命名实体识别系统接口及说明
   - 实现微博语料预处理
2. 2016年8月6日 - 2016年11月5日
   - 实现面向微博语料的分词系统
   - 实现面向已分词微博语料的词性标注系统、命名实体识别系统
   - 系统前期的任务继续完善
   - 粗略实现面向微博语料的中文词法分析系统
3. 2016年11月6日 - 2017年2月5日
   - 根据出现的各种错误、误差分析结果，寻求改进方法和措施
   - 实现上述功能，整合系统
4. 2017年2月6日 - 2017年5月1日
   - 可以在运营商平台运行测试
   - 准备验收结题材料，项目结题鉴定

## 五、实践工作的预期成果及成果提交形式

### 1、预期成果

​	（1）提出面向微博语料的中文词法分析算法；

​	（2）搭建一个准确率高，效率高，可移植的微博语料中文词法分析原型系统；

​	（3）发表学术论文、申请专利或软件著作权登记1-2篇（项）。

## 六、实践基础和工作条件

（申请人与本课题有关的实践研究成果，含承担项目、发表论文、获奖、国内外评价与引用情况；现有的主要仪器设备、研究技术及协作条件等）

### 1）实践基础

项目申请人的导师夏睿一直从事自然语言处理、人工智能、机器学习和数据挖掘等方 面的研究工作。在自然语言处理和人工智能领域的顶级国际学术期刊和学术会议(IEEE IS、 Information Sciences、IJCAI、AAAI、ACL、COLING 和 IJCNLP 等)上发表高质量学术论 文 10 余篇。他曾担任国际会议 IJCAI (2013)、COLING (2014)、WWW Workshop on MABSDA (2013)、ACM KDD Workshop on WISDOM (2012, 2013)、IEEE ICDM Workshop on SENTIRE (2011, 2012, 2013) 的程序委员会委员,并担任国际期刊 Data Mining and Knowledge Discovery (2014)、IEEE IS (2012)、IEEE CIM (2013)、ACM TALIP (2010)、JCST (2011)、 计算机学报 (2014)、自动化学报 (2012, 2013) 和国际会议 IJCAI (2013), COLING (2010, 2014), IEEE NLPKE (2008, 2009) 的审稿人。

### 2）工作条件

项目申请人所在的研究单位为南京理工大学计算机科学与技术学院,拥有“模式识别与智能系统”国家重点学科,依托于“高维信息智能感知与系统”教育部重点实验室,拥有良好的硬件设备和研究环境,具备若干台计算机和高性能服务器,网络环境良好,图书资料齐全,为本项目的研究工作提供了很好的支持和保障。
## 七、经费概算（单位：万元）
| 支出科目 |  金额  |   计算根据及理由    |
| :--: | :--: | :----------: |
| 交通支出 | 0.5  |     差旅费      |
| 参加会议 | 0.5  | 根据学术需要参加会议支持 |
| 人员补贴 | 0.5  | 4个人1年的项目研究经费 |
|  合计  | 1.5  |    项目申请经费    |